import json
import time
import os
import re
import sqlite3
from typing import Any, Dict, List, Optional, Callable
from datetime import datetime
import warnings
import asyncio
import inspect
import logging
import google.generativeai as genai

# Configuration Agent Morphius - NÃ¼mtema AGENCY
GLOBAL_CONFIG = {
    "database_path": "logs/agent_memory.db",
    "log_file_path": "logs/agent_log.jsonl",
    "memory_file": "logs/agent_experience.json",
    "owner_info": {
        "framework_origin": "NÃ¼mtema AGENCY",
        "website": "https://www.numtemaagency.com",
        "contact_phone": "07 45 43 42 40",
    },
    "logical_symbols": {
        "Necessarily": "â–¡", "Possibly": "â—‡", "Therefore": "âˆ´", "Uncertain": "?", "Not": "Â¬",
        "And": "âˆ§", "Or": "âˆ¨", "If...Then": "â†’", "Iff": "â†”",
    },
    "llm_model_configs": {
        "creative": "gemini-2.5-pro",
        "fast_draft": "gemini-2.5-flash", 
        "function_call": "gemini-2.5-flash",
        "general": "gemini-2.5-flash",
        "optimization": "gemini-2.5-pro",
        "analysis": "gemini-2.5-pro"
    }
}

# Configurer Gemini
genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))

class AgentMorphius:
    """Agent Morphius - Optimisation IA des Funnels"""
    
    def __init__(self):
        self.models = GLOBAL_CONFIG["llm_model_configs"]
        self.memory = self._load_memory()
        self.reasoning_schema = {
            "mode": "RRLA",
            "available_modes": ["RRLA", "MORPHIUSVISION", "PILOTPROMPT", "STRATOS"],
            "wm": {"g": "", "sg": "", "ctx": "", "pr": {"completed": [], "current": {}}},
            "chain": {"steps": [], "reflect": "", "note": [], "warn": [], "err": []},
            "kg": {"tri": []},
            "logic": {"propos": [], "proofs": [], "crits": [], "doubts": [], "rules": []}
        }
    
    def _load_memory(self) -> Dict:
        """Charge la mÃ©moire expÃ©rientielle de l'agent"""
        try:
            if os.path.exists(GLOBAL_CONFIG["memory_file"]):
                with open(GLOBAL_CONFIG["memory_file"], 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logging.error(f"Erreur chargement mÃ©moire: {e}")
        return {"optimizations": [], "patterns": [], "best_practices": []}
    
    def _save_memory(self):
        """Sauvegarde la mÃ©moire expÃ©rientielle"""
        try:
            os.makedirs(os.path.dirname(GLOBAL_CONFIG["memory_file"]), exist_ok=True)
            with open(GLOBAL_CONFIG["memory_file"], 'w', encoding='utf-8') as f:
                json.dump(self.memory, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"Erreur sauvegarde mÃ©moire: {e}")
    
    async def analyze_funnel(self, funnel_data: Dict) -> Dict:
        """Analyse complÃ¨te d'un funnel avec Gemini 2.5 Pro"""
        
        model = genai.GenerativeModel(self.models["analysis"])
        
        prompt = f"""
        ðŸ§  AGENT MORPHIUS - ANALYSE FUNNEL
        Framework: NÃ¼mtema AGENCY
        
        Analysez ce funnel de maniÃ¨re approfondie:
        
        DONNÃ‰ES FUNNEL:
        {json.dumps(funnel_data, ensure_ascii=False, indent=2)}
        
        MÃ‰MOIRE EXPÃ‰RIENTIELLE:
        {json.dumps(self.memory, ensure_ascii=False, indent=2)}
        
        ANALYSE DEMANDÃ‰E:
        1. Score global (/100)
        2. PrÃ©diction taux de conversion
        3. Points forts identifiÃ©s
        4. ProblÃ¨mes dÃ©tectÃ©s avec solutions
        5. Recommandations d'optimisation
        6. Analyse psychologique du parcours
        7. Suggestions d'A/B testing
        
        RÃ‰PONDEZ EN JSON STRUCTURÃ‰:
        {{
            "overall_score": 0-100,
            "conversion_prediction": 0.0-100.0,
            "strengths": ["point fort 1", "point fort 2"],
            "issues": [
                {{
                    "problem": "description du problÃ¨me",
                    "solution": "solution recommandÃ©e", 
                    "impact": "impact estimÃ© en %",
                    "priority": "high|medium|low"
                }}
            ],
            "recommendations": [
                {{
                    "type": "optimization|design|content|flow",
                    "description": "description de la recommandation",
                    "expected_improvement": "amÃ©lioration attendue",
                    "implementation_difficulty": "easy|medium|hard"
                }}
            ],
            "psychological_analysis": {{
                "user_journey_flow": "analyse du parcours",
                "friction_points": ["point de friction 1"],
                "engagement_factors": ["facteur d'engagement 1"]
            }},
            "ab_test_suggestions": [
                {{
                    "element": "Ã©lÃ©ment Ã  tester",
                    "variant_a": "version actuelle",
                    "variant_b": "version proposÃ©e",
                    "hypothesis": "hypothÃ¨se du test"
                }}
            ],
            "confidence_level": 0.0-1.0,
            "processing_time": "temps de traitement"
        }}
        """
        
        try:
            start_time = time.time()
            response = await model.generate_content_async(prompt)
            processing_time = time.time() - start_time
            
            # Parser la rÃ©ponse JSON
            analysis_text = response.text
            # Nettoyer la rÃ©ponse pour extraire le JSON
            json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                analysis["processing_time"] = f"{processing_time:.2f}s"
                analysis["agent"] = "Morphius v2.1"
                analysis["model_used"] = self.models["analysis"]
                
                # Sauvegarder dans la mÃ©moire
                self.memory["optimizations"].append({
                    "timestamp": datetime.now().isoformat(),
                    "funnel_id": funnel_data.get("id", "unknown"),
                    "analysis": analysis
                })
                self._save_memory()
                
                return analysis
            else:
                raise ValueError("Impossible de parser la rÃ©ponse JSON")
                
        except Exception as e:
            logging.error(f"Erreur analyse funnel: {e}")
            return {
                "error": str(e),
                "overall_score": 0,
                "conversion_prediction": 0.0,
                "agent": "Morphius v2.1"
            }
    
    async def optimize_step(self, step_data: Dict, funnel_context: Dict) -> Dict:
        """Optimise une Ã©tape spÃ©cifique avec Gemini 2.5 Pro"""
        
        model = genai.GenerativeModel(self.models["optimization"])
        
        prompt = f"""
        ðŸ§  AGENT MORPHIUS - OPTIMISATION Ã‰TAPE
        Framework: NÃ¼mtema AGENCY
        
        Ã‰TAPE Ã€ OPTIMISER:
        {json.dumps(step_data, ensure_ascii=False, indent=2)}
        
        CONTEXTE FUNNEL:
        {json.dumps(funnel_context, ensure_ascii=False, indent=2)}
        
        MÃ‰MOIRE EXPÃ‰RIENTIELLE:
        Optimisations prÃ©cÃ©dentes: {len(self.memory.get("optimizations", []))}
        Patterns identifiÃ©s: {self.memory.get("patterns", [])}
        
        OPTIMISATION DEMANDÃ‰E:
        1. Titre optimisÃ© (plus engageant)
        2. Contenu amÃ©liorÃ© (psychologie persuasive)
        3. Options de rÃ©ponse optimisÃ©es
        4. Suggestions visuelles
        5. Micro-copy amÃ©liorÃ©
        6. Analyse des biais cognitifs
        
        RÃ‰PONDEZ EN JSON:
        {{
            "optimized_title": "nouveau titre optimisÃ©",
            "optimized_content": "nouveau contenu optimisÃ©", 
            "optimized_options": ["option 1 optimisÃ©e", "option 2 optimisÃ©e"],
            "visual_suggestions": [
                {{
                    "element": "Ã©lÃ©ment visuel",
                    "suggestion": "suggestion d'amÃ©lioration",
                    "reasoning": "justification psychologique"
                }}
            ],
            "microcopy_improvements": [
                {{
                    "original": "texte original",
                    "improved": "texte amÃ©liorÃ©",
                    "reason": "raison de l'amÃ©lioration"
                }}
            ],
            "cognitive_biases_applied": [
                {{
                    "bias": "nom du biais",
                    "application": "comment il est appliquÃ©",
                    "expected_impact": "impact attendu"
                }}
            ],
            "expected_improvement": "pourcentage d'amÃ©lioration attendu",
            "confidence": 0.0-1.0
        }}
        """
        
        try:
            response = await model.generate_content_async(prompt)
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            
            if json_match:
                optimization = json.loads(json_match.group())
                optimization["agent"] = "Morphius v2.1"
                optimization["model_used"] = self.models["optimization"]
                optimization["timestamp"] = datetime.now().isoformat()
                
                return optimization
            else:
                raise ValueError("Impossible de parser la rÃ©ponse JSON")
                
        except Exception as e:
            logging.error(f"Erreur optimisation Ã©tape: {e}")
            return {"error": str(e), "agent": "Morphius v2.1"}
    
    async def generate_insights(self, user_data: Dict) -> List[Dict]:
        """GÃ©nÃ¨re des insights personnalisÃ©s avec Gemini 2.5 Flash"""
        
        model = genai.GenerativeModel(self.models["fast_draft"])
        
        prompt = f"""
        ðŸ§  AGENT MORPHIUS - INSIGHTS PERSONNALISÃ‰S
        Framework: NÃ¼mtema AGENCY
        
        DONNÃ‰ES UTILISATEUR:
        {json.dumps(user_data, ensure_ascii=False, indent=2)}
        
        GÃ‰NÃ‰REZ 5 INSIGHTS PERSONNALISÃ‰S:
        - Tendances dÃ©tectÃ©es
        - OpportunitÃ©s d'optimisation
        - Alertes de performance
        - Recommandations stratÃ©giques
        - PrÃ©dictions de marchÃ©
        
        FORMAT JSON:
        [
            {{
                "type": "optimization|trend|alert|recommendation|prediction",
                "title": "Titre de l'insight",
                "message": "Message dÃ©taillÃ©",
                "priority": "high|medium|low",
                "impact": "impact estimÃ©",
                "action_required": "action recommandÃ©e",
                "confidence": 0.0-1.0
            }}
        ]
        """
        
        try:
            response = await model.generate_content_async(prompt)
            json_match = re.search(r'\[.*\]', response.text, re.DOTALL)
            
            if json_match:
                insights = json.loads(json_match.group())
                for insight in insights:
                    insight["agent"] = "Morphius v2.1"
                    insight["timestamp"] = datetime.now().isoformat()
                
                return insights
            else:
                return []
                
        except Exception as e:
            logging.error(f"Erreur gÃ©nÃ©ration insights: {e}")
            return []
    
    async def predict_conversion(self, funnel_data: Dict, historical_data: List[Dict]) -> Dict:
        """PrÃ©dit le taux de conversion avec Gemini 2.5 Pro"""
        
        model = genai.GenerativeModel(self.models["analysis"])
        
        prompt = f"""
        ðŸ§  AGENT MORPHIUS - PRÃ‰DICTION CONVERSION
        Framework: NÃ¼mtema AGENCY
        
        FUNNEL ACTUEL:
        {json.dumps(funnel_data, ensure_ascii=False, indent=2)}
        
        DONNÃ‰ES HISTORIQUES:
        {json.dumps(historical_data[-10:], ensure_ascii=False, indent=2)}  # 10 derniers
        
        PRÃ‰DICTION DEMANDÃ‰E:
        1. Taux de conversion prÃ©dit
        2. Intervalle de confiance
        3. Facteurs influenÃ§ant la prÃ©diction
        4. ScÃ©narios optimiste/pessimiste
        5. Recommandations pour amÃ©liorer
        
        RÃ‰PONDEZ EN JSON:
        {{
            "predicted_conversion_rate": 0.0-100.0,
            "confidence_interval": {{"min": 0.0, "max": 100.0}},
            "influencing_factors": [
                {{
                    "factor": "nom du facteur",
                    "impact": "positif|nÃ©gatif|neutre",
                    "weight": 0.0-1.0
                }}
            ],
            "scenarios": {{
                "optimistic": {{"rate": 0.0, "conditions": "conditions optimales"}},
                "realistic": {{"rate": 0.0, "conditions": "conditions normales"}},
                "pessimistic": {{"rate": 0.0, "conditions": "conditions dÃ©favorables"}}
            }},
            "improvement_recommendations": [
                {{
                    "action": "action recommandÃ©e",
                    "expected_lift": "amÃ©lioration attendue en %",
                    "effort_required": "effort nÃ©cessaire"
                }}
            ],
            "model_confidence": 0.0-1.0
        }}
        """
        
        try:
            response = await model.generate_content_async(prompt)
            json_match = re.search(r'\{.*\}', response.text, re.DOTALL)
            
            if json_match:
                prediction = json.loads(json_match.group())
                prediction["agent"] = "Morphius v2.1"
                prediction["timestamp"] = datetime.now().isoformat()
                
                return prediction
            else:
                raise ValueError("Impossible de parser la prÃ©diction")
                
        except Exception as e:
            logging.error(f"Erreur prÃ©diction conversion: {e}")
            return {"error": str(e), "predicted_conversion_rate": 0.0}

# Instance globale de l'agent
agent_morphius = AgentMorphius()

# Fonctions utilitaires pour l'API
async def analyze_funnel_with_ai(funnel_data: Dict) -> Dict:
    """Interface pour l'API d'analyse"""
    return await agent_morphius.analyze_funnel(funnel_data)

async def optimize_step_with_ai(step_data: Dict, funnel_context: Dict) -> Dict:
    """Interface pour l'API d'optimisation"""
    return await agent_morphius.optimize_step(step_data, funnel_context)

async def generate_user_insights(user_data: Dict) -> List[Dict]:
    """Interface pour l'API d'insights"""
    return await agent_morphius.generate_insights(user_data)

async def predict_funnel_conversion(funnel_data: Dict, historical_data: List[Dict]) -> Dict:
    """Interface pour l'API de prÃ©diction"""
    return await agent_morphius.predict_conversion(funnel_data, historical_data)

if __name__ == "__main__":
    # Test de l'agent
    import asyncio
    
    test_funnel = {
        "id": "test-funnel-1",
        "title": "Test Funnel",
        "steps": [
            {"type": "welcome", "title": "Bienvenue", "content": "Test"},
            {"type": "question", "title": "Question 1", "content": "Votre Ã¢ge ?"}
        ]
    }
    
    async def test_agent():
        print("ðŸ§  Test Agent Morphius...")
        analysis = await agent_morphius.analyze_funnel(test_funnel)
        print("Analyse:", json.dumps(analysis, ensure_ascii=False, indent=2))
    
    asyncio.run(test_agent())
